{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision.datasets import mnist\n",
    "from torch import nn,optim\n",
    "from torch.autograd import variable\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(x):\n",
    "    x = np.array(x, dtype='float32') / 255\n",
    "    x = (x-0.5)/0.5\n",
    "    x = x.reshape((-1, 1))\n",
    "    x = torch.from_numpy(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = mnist.MNIST('./dataSet', train=True, transform=tf, download = True)\n",
    "test_set = mnist.MNIST('./dataSet', train=False, transform=tf, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_data = DataLoader(test_set, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(net, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(784, 400), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(400, 200), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(200, 100), \n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Linear(100, 10), \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "net(\n",
       "  (layer1): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=200, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net = net.to(device)\n",
    "net = net().cuda()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, Train Loss:0.063712, Train Acc:0.981910, Eval Loss:0.091353, Eval Acc:0.971816\n",
      "epoch:1, Train Loss:0.060604, Train Acc:0.982276, Eval Loss:0.090580, Eval Acc:0.972706\n",
      "epoch:2, Train Loss:0.057430, Train Acc:0.983276, Eval Loss:0.092560, Eval Acc:0.971519\n",
      "epoch:3, Train Loss:0.052466, Train Acc:0.985374, Eval Loss:0.086884, Eval Acc:0.972607\n",
      "epoch:4, Train Loss:0.050286, Train Acc:0.985558, Eval Loss:0.081498, Eval Acc:0.975178\n",
      "epoch:5, Train Loss:0.046410, Train Acc:0.986657, Eval Loss:0.081776, Eval Acc:0.974090\n",
      "epoch:6, Train Loss:0.044228, Train Acc:0.987307, Eval Loss:0.094227, Eval Acc:0.970431\n",
      "epoch:7, Train Loss:0.041638, Train Acc:0.988140, Eval Loss:0.080332, Eval Acc:0.977255\n",
      "epoch:8, Train Loss:0.039024, Train Acc:0.988956, Eval Loss:0.077081, Eval Acc:0.976365\n",
      "epoch:9, Train Loss:0.036473, Train Acc:0.990205, Eval Loss:0.077138, Eval Acc:0.976068\n",
      "epoch:10, Train Loss:0.034372, Train Acc:0.990922, Eval Loss:0.081934, Eval Acc:0.974782\n",
      "epoch:11, Train Loss:0.032719, Train Acc:0.990922, Eval Loss:0.074029, Eval Acc:0.977057\n",
      "epoch:12, Train Loss:0.030319, Train Acc:0.991688, Eval Loss:0.081097, Eval Acc:0.975672\n",
      "epoch:13, Train Loss:0.028802, Train Acc:0.992487, Eval Loss:0.080882, Eval Acc:0.974486\n",
      "epoch:14, Train Loss:0.026287, Train Acc:0.993503, Eval Loss:0.074557, Eval Acc:0.976661\n",
      "epoch:15, Train Loss:0.025036, Train Acc:0.993670, Eval Loss:0.073666, Eval Acc:0.978046\n",
      "epoch:16, Train Loss:0.023540, Train Acc:0.994136, Eval Loss:0.072563, Eval Acc:0.977453\n",
      "epoch:17, Train Loss:0.021734, Train Acc:0.994570, Eval Loss:0.087096, Eval Acc:0.972607\n",
      "epoch:18, Train Loss:0.020880, Train Acc:0.994953, Eval Loss:0.074261, Eval Acc:0.979035\n",
      "epoch:19, Train Loss:0.019304, Train Acc:0.995436, Eval Loss:0.076324, Eval Acc:0.977453\n",
      "epoch:20, Train Loss:0.017885, Train Acc:0.995886, Eval Loss:0.082106, Eval Acc:0.977156\n",
      "epoch:21, Train Loss:0.016935, Train Acc:0.996152, Eval Loss:0.094629, Eval Acc:0.972508\n",
      "epoch:22, Train Loss:0.015830, Train Acc:0.996535, Eval Loss:0.070803, Eval Acc:0.978738\n",
      "epoch:23, Train Loss:0.014579, Train Acc:0.997135, Eval Loss:0.070860, Eval Acc:0.978738\n",
      "epoch:24, Train Loss:0.013733, Train Acc:0.997351, Eval Loss:0.072684, Eval Acc:0.977947\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "acces = []\n",
    "eval_losses = []\n",
    "eval_acces = []\n",
    "for e in range(30):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    net.train()\n",
    "    for im, label in train_data:\n",
    "        im = im.view(im.size(0), -1)\n",
    "        im = im.to(device)\n",
    "        label = label.to(device)\n",
    "        # 前向传播\n",
    "        out = net(im)\n",
    "        loss = criterion(out, label)\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 记录误差\n",
    "        train_loss += loss.item()\n",
    "        # 计算分类的准确率\n",
    "        _, pred = out.max(1)\n",
    "        num_correct = (pred == label).sum().item()\n",
    "        acc = num_correct / im.shape[0]\n",
    "        train_acc += acc\n",
    " \n",
    "    losses.append(train_loss / len(train_data))\n",
    "    acces.append(train_acc / len(train_data))\n",
    "    # 在测试集上检验效果\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    net.eval()\n",
    "    for im, label in test_data:\n",
    "        im = im.view(im.size(0), -1)\n",
    "        im = im.to(device)\n",
    "        label = label.to(device)\n",
    "        out = net(im)\n",
    "        loss = criterion(out, label)\n",
    "        # 记录误差\n",
    "        eval_loss += loss.item()\n",
    "        # 记录准确率\n",
    "        _, pred = out.max(1)\n",
    "        num_correct = (pred == label).sum().item()\n",
    "        acc = num_correct / im.shape[0]\n",
    "        eval_acc += acc\n",
    "    \n",
    "    eval_losses.append(eval_loss / len(test_data))\n",
    "    eval_acces.append(eval_acc / len(test_data))\n",
    "    print('epoch:{}, Train Loss:{:.6f}, Train Acc:{:.6f}, Eval Loss:{:.6f}, Eval Acc:{:.6f}'\n",
    "          .format(e, train_loss/len(train_data), train_acc / len(train_data),\n",
    "                 eval_loss / len(test_data), eval_acc / len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch for Deeplearning",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
